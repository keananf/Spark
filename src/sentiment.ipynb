{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spark import Spark\n",
    "import pandas as pd\n",
    "import src.tweet_volume as funcs\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as fs\n",
    "from src.plotting import double_plot\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "import src.nlp.clean as clean\n",
    "from pyspark.sql.types import StringType, IntegerType, StructField, StructType\n",
    "from src.nlp.sentiment import SentimentAnalyser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = Spark('load', 'local[4]')\n",
    "sess = spark.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = funcs.load_dataframe(sess, '/cs/unique/ls99-kf39-cs5052/data/tweets/*.json', funcs.schema)\n",
    "df2 = funcs.parse_timestamp(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(target=0, text=u'is so sad for my apl friend')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_schema = StructType([\n",
    "    StructField(\"target\", IntegerType(), True),\n",
    "    StructField(\"text\", StringType(), True)\n",
    "])\n",
    "\n",
    "train_df = sess.read.csv(\"/cs/unique/ls99-kf39-cs5052/train/train.csv\", header=True, schema=sent_schema)\n",
    "\n",
    "train_clean = clean.clean_tweets(train_df, \"text\")\n",
    "train_clean.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets in train: 1,434,200\n"
     ]
    }
   ],
   "source": [
    "train, evaluation = train_clean.randomSplit([0.99, 0.1], seed=42)\n",
    "print(\"Number of tweets in train: {:,}\".format(train.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = \"/cs/unique/ls99-kf39-cs5052/models/pipeline\"\n",
    "classifier = \"/cs/unique/ls99-kf39-cs5052/models/linreg\"\n",
    "\n",
    "sentiment_model = SentimentAnalyser()\n",
    "sentiment_model.load(pipeline, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading KRAKEN_DASH_EUR.csv\nLoading KRAKEN_LTC_EUR.csv\nLoading KRAKEN_BTC_EUR.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading KRAKEN_ETC_EUR.csv\nLoading KRAKEN_BCH_EUR.csv\nLoading KRAKEN_XMR_EUR.csv\nLoading KRAKEN_ETH_EUR.csv\n"
     ]
    }
   ],
   "source": [
    "alts = ['BTC', 'XMR', 'DASH', 'LTC', 'ETC', 'BCH']  # 'ETH'\n",
    "hashes = {\n",
    "        'ETH': ['%ethereum%', '%ether%', '%eth%'],\n",
    "        'BTC': ['%bitcoin%', '%btc%', '%bitcoin%'],\n",
    "        'XMR': [\"%monero%\", \"%xmr%\", \"%monero%\"], \n",
    "        'DASH': [\"%digital cash%\", \"%dash%\", \"%dash%\"], \n",
    "        'LTC': [\"%litecoin%\", \"%ltc%\", \"%litecoin%\"], \n",
    "        'ETC': [\"%ethereum classic%\", \"%etc%\", \"%eth classic%\"], \n",
    "        'BCH': [\"%bitcoincash%\", \"%bch%\", \"%bitcoin cash%\"]\n",
    "    }\n",
    "\n",
    "crypto_data = funcs.load_crypto()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at BTC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @vinnylingham2x #bitcoin needs less developers and more incumbents and intermediaries \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets positive: 2,753,006, negative: 403,501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment-Price correlation: -0.1724\nSentiment-Return correlation: -0.5240\nLooking at XMR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @andrew0hayes genesis mining discountnpj8st#btc #ltc #eth #xmr #dash #str #gnt #dgb #stratis #xlm #eos #iota…\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets positive: 34,201, negative: 8,696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment-Price correlation: 0.8958\nSentiment-Return correlation: 0.2364\nLooking at DASH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @ken2020n 1027 あさイチ二宮和也1027 ロンドンハーツ2時間sp二宮和也1028 ラストレシピ公開直前！絶品グルメ打ち上げツアー二宮和也1029 鉄腕dash二宮和也112 アメトーーク二宮和也1112 相葉マナ…\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets positive: 451,318, negative: 116,419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment-Price correlation: -0.3727\nSentiment-Return correlation: -0.6164\nLooking at LTC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @andrew0hayes genesis mining discountnpj8st#btc #ltc #eth #xmr #dash #str #gnt #dgb #stratis #xlm #eos #iota…\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets positive: 214,838, negative: 37,729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment-Price correlation: 0.4713\nSentiment-Return correlation: -0.0315\nLooking at ETC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @andrew0hayes #genesismining code npj8st $etc $xmr #litecoin $ltc $steem $zec $dash $btc $eth $rep #eth… \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets positive: 46,498, negative: 3,611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment-Price correlation: -0.2842\nSentiment-Return correlation: -0.5320\nLooking at BCH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @lisaciarlone what the fork bitcoin cash community preps hard fork slated for november 13 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets positive: 196,321, negative: 61,832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment-Price correlation: 0.5710\nSentiment-Return correlation: -0.1822\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for coin in alts:\n",
    "    hash = hashes[coin]\n",
    "    coin_df = df2.filter(fs.lower(df['text']).like(hash[0]) | fs.lower(df['text']).like(hash[1]) | fs.lower(df['text']).like(hash[2]))\n",
    "    coin_clean = clean.clean_tweets(coin_df, \"text\")\n",
    "    print(\"Looking at %s\" % coin)\n",
    "    print(coin_clean.first().text)\n",
    "    \n",
    "    coin_pred = sentiment_model.predict(coin_clean)\n",
    "    pos, neg = sentiment_model.count_sentiments(coin_pred)\n",
    "    \n",
    "    daily_pos = funcs.aggregate_by_day(pos)\n",
    "    daily_neg = funcs.aggregate_by_day(neg)\n",
    "    daily_pos.set_index(\"date\", inplace=True)\n",
    "    daily_neg.set_index(\"date\", inplace=True)\n",
    "    daily_pos.index = pd.to_datetime(daily_pos.index)\n",
    "    daily_neg.index = pd.to_datetime(daily_neg.index)\n",
    "    \n",
    "    daily_sent = pd.DataFrame(data={'pos':daily_pos['count'], 'neg':daily_neg['count']}, index=daily_pos.index)\n",
    "    daily_sent['pos'] = daily_sent['pos'].astype(float)\n",
    "    daily_sent['neg'] = daily_sent['neg'].astype(float)\n",
    "    daily_sent['sentiment'] = (daily_sent['pos'] - daily_sent['neg']) / (daily_sent['pos'] + daily_sent['neg'])\n",
    "    \n",
    "    # Fetch coin price data, combine with sentiment score and plot.\n",
    "    coin_df = crypto_data[coin]\n",
    "    sent_price = coin_df\n",
    "    sent_price['price'] = sent_price.weightedAverage\n",
    "    sent_price['return'] = sent_price.price.pct_change()\n",
    "    sent_price['sentiment'] = daily_sent['sentiment']\n",
    "    sent_price.dropna(inplace=True)\n",
    "    \n",
    "    double_plot([sent_price.price, sent_price.sentiment], \n",
    "                ['%s Price' % coin, 'Sentiment'], \n",
    "                ['Date', 'Price', 'Sentiment Score'], \n",
    "                \"%s Price vs Tweet Sentiment\" % coin, \n",
    "                sent_price.index.tolist())\n",
    "    double_plot([sent_price['return'], sent_price.sentiment], \n",
    "                ['%s Return' % coin, 'Sentiment'], \n",
    "                ['Date', 'Price', 'Sentiment Score'], \n",
    "                \"%s Return vs Tweet Sentiment\" % coin, \n",
    "                sent_price.index.tolist())\n",
    "    print(\"Sentiment-Price correlation: %.4f\" % sent_price.corr().sentiment.price)\n",
    "    print(\"Sentiment-Return correlation: %.4f\" % sent_price.corr()['sentiment']['return'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment-Price correlation: -0.0452\n"
     ]
    }
   ],
   "source": [
    "daily_sent = pd.DataFrame(data={'pos':daily_pos['count'], 'neg':daily_neg['count']}, index=daily_pos.index)\n",
    "daily_sent['pos'] = daily_sent['pos'].astype(float)\n",
    "daily_sent['neg'] = daily_sent['neg'].astype(float)\n",
    "daily_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment-Price correlation: -0.0452\n"
     ]
    }
   ],
   "source": [
    "\n",
    "daily_sent['sentiment'] = (daily_sent['pos'] - daily_sent['neg']) / (daily_sent['pos'] + daily_sent['neg'])\n",
    "daily_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment-Price correlation: -0.0452\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fetch coin price data, combine with sentiment score and plot.\n",
    "coin_df = crypto_data[coin]\n",
    "sent_price = coin_df\n",
    "sent_price['price'] = sent_price.weightedAverage\n",
    "sent_price['return'] = sent_price.price.pct_change()\n",
    "sent_price['sentiment'] = daily_sent['sentiment']\n",
    "sent_price.dropna(inplace=True)\n",
    "\n",
    "double_plot([sent_price['return'], sent_price.sentiment], \n",
    "            ['%s Price' % coin, 'Sentiment'], \n",
    "            ['Date', 'Price', 'Sentiment Score'], \n",
    "            \"%s Price vs Tweet Sentiment\" % coin, \n",
    "            sent_price.index.tolist())\n",
    "print(\"Sentiment-Price correlation: %.4f\" % sent_price.corr()['sentiment']['return'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
