{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spark import Spark\n",
    "import src.tweet_volume as funcs\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as fs\n",
    "import os \n",
    "import pandas as pd\n",
    "from src.plotting import double_plot\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import src.nlp.clean as clean\n",
    "from pyspark.sql.types import StringType, IntegerType, StructField, StructType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = Spark('load', 'local')\n",
    "sess = spark.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = funcs.load_dataframe(sess, '/cs/home/ls99/PycharmProjects/Spark/data/*.json', funcs.schema)\n",
    "df2 = funcs.parse_timestamp(df)\n",
    "eth_df = df2.filter(fs.lower(df['text']).like(\"%ether%\") | fs.lower(df['text']).like(\"%eth%\") | fs.lower(df['text']).like(\"%ethereum%\"))\n",
    "eth_clean = clean.clean_tweets(eth_df, \"text\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u' #ethereum #eth'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_clean.first().text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_schema = StructType([\n",
    "    StructField(\"target\", IntegerType(), True),\n",
    "    StructField(\"text\", StringType(), True)\n",
    "])\n",
    "\n",
    "train_df = sess.read.csv(\"/cs/unique/ls99-kf39-cs5052/train/train.csv\", header=True, schema=sent_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(target=0, text=u'                     is so sad for my APL friend.............')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = clean.clean_tweets(train_df, \"text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets in train: 1,434,200\n"
     ]
    }
   ],
   "source": [
    "eth_train, eth_eval = train_clean.randomSplit([0.99, 0.1], seed=42)\n",
    "print(\"Number of tweets in train: {:,}\".format(eth_train.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram, VectorAssembler, CountVectorizer\n",
    "\n",
    "\n",
    "def ngram_model(input_col=(\"text\", \"target\"), n=3):\n",
    "    tokeniser = [Tokenizer(inputCol=input_col[0], outputCol=\"words\")]\n",
    "    ngrams = [\n",
    "        NGram(n=i, inputCol=\"words\", outputCol=\"%d_grams\" % i) for i in range(1, n + 1)\n",
    "    ]\n",
    "    count_vectoriser = [\n",
    "        CountVectorizer(vocabSize=5000, inputCol=\"%d_grams\" % i, outputCol=\"%d_tf\" % i) for i in range(1, n+1)\n",
    "    ]\n",
    "    inverse_doc_freq = [\n",
    "        IDF(inputCol=\"%d_tf\" % i, outputCol=\"%d_idf\" %i, minDocFreq=5) for i in range(1, n + 1)\n",
    "    ]\n",
    "    \n",
    "    vector_assembler = [\n",
    "        VectorAssembler(inputCols=[\"%d_idf\" % i for i in range(1, n+1)], outputCol=\"features\")\n",
    "    ]\n",
    "    \n",
    "    string_index = [\n",
    "        StringIndexer(inputCol=input_col[1], outputCol=\"label\", handleInvalid=\"keep\")\n",
    "    ]\n",
    "    \n",
    "    return Pipeline(stages=tokeniser + ngrams + count_vectoriser + inverse_doc_freq + vector_assembler + string_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RocAuc: 0.8661, Accuracy: 0.7906\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def simple_tfidf_model(input_col=(\"text\",\"target\")):\n",
    "    tokeniser = Tokenizer(inputCol=input_col[0], outputCol=\"words\")\n",
    "    hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol=\"tf\")\n",
    "    idf = IDF(inputCol=\"tf\", outputCol=\"features\", minDocFreq=5)\n",
    "    \n",
    "    string_index = StringIndexer(inputCol=input_col[1], outputCol=\"label\", handleInvalid=\"keep\")\n",
    "    pipeline = Pipeline(stages=[tokeniser, hashtf, idf, string_index])\n",
    "    \n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RocAuc: 0.8661, Accuracy: 0.7906\n"
     ]
    }
   ],
   "source": [
    "pipeline = ngram_model()\n",
    "\n",
    "# Sentiment feature selection pipeline\n",
    "ngram_pipeline = pipeline.fit(eth_train)\n",
    "eth_train_df = ngram_pipeline.transform(eth_train)\n",
    "eth_eval_df = ngram_pipeline.transform(eth_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RocAuc: 0.8661, Accuracy: 0.7906\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fit a classifier to classify as either positive or negative sentiment\n",
    "lr = LogisticRegression(maxIter=100, regParam=0.1)\n",
    "classifier = lr.fit(eth_train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RocAuc: 0.8661, Accuracy: 0.7906\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = classifier.transform(eth_eval_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RocAuc: 0.8661, Accuracy: 0.7906\n"
     ]
    }
   ],
   "source": [
    "report = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "\n",
    "def classification_report(predictions):\n",
    "    bin_rep = report.evaluate(predictions)\n",
    "    accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(eth_eval_df.count())\n",
    "\n",
    "    print(\"RocAuc: %.4f, Accuracy: %.4f\" % (bin_rep, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_pipeline.save(\"/cs/unique/ls99-kf39-cs5052/models/pipeline\")\n",
    "classifier.save(\"/cs/unique/ls99-kf39-cs5052/models/linreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_model = PipelineModel.load(\"/cs/unique/ls99-kf39-cs5052/models/pipeline\")\n",
    "classifier = LogisticRegressionModel.load(\"/cs/unique/ls99-kf39-cs5052/models/linreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ether tweets positive: 13369.000000, negative: 1022.000000\n"
     ]
    }
   ],
   "source": [
    "eth_transformed = ngram_pipeline.transform(eth_clean)\n",
    "eth_pred = classifier.transform(eth_transformed)\n",
    "\n",
    "positive = eth_pred.filter(eth_pred.prediction == 0.0).count()\n",
    "negative = eth_pred.filter(eth_pred.prediction == 1.0).count()\n",
    "\n",
    "print(\"Ether tweets positive: {:,}, negative: {:,}\".format(positive, negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
