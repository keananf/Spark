{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Sentiment Analysis\n",
    "\n",
    "The aim of this notebook is to train a classifier for sentiment analysis using tweet data, then to assign sentiment scores\n",
    "to a group of tweets collected for a set of cryptocurrnecies over the period of a month. This will then be used to plot some correlation\n",
    "graphs of price and return versus sentiment score at a daily frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spark import Spark\n",
    "import pandas as pd\n",
    "import src.tweet_volume as funcs\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as fs\n",
    "from src.plotting import double_plot\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "import src.nlp.clean as clean\n",
    "from pyspark.sql.types import StringType, IntegerType, StructField, StructType\n",
    "from src.nlp.sentiment import SentimentAnalyser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Spark and Data\n",
    "\n",
    "For this we are going to use a Spark SQL Session, as the SQL package contains methods for reading CSV and JSON data into Dataframes.\n",
    "We start a new Spark session by passing the URL of the master process we want to connect to. This can either be 'local' or a remote master process specified by a Spark URL. Here we will connect to a remote Spark master which has 25 nodes connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = Spark('load', 'local')\n",
    "sess = spark.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweet json is preprocessed with a Schema which will select only necessary fields from the data read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = funcs.load_dataframe(sess, '/cs/unique/ls99-kf39-cs5052/data/tweets/*.json', funcs.schema)\n",
    "df2 = funcs.parse_timestamp(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n",
    "\n",
    "Likewise, we need some training data for the algorithms, which is another set of tweets that has been pre-labelled for sentiment. The labels are `positive` and `negative`, identified by a `0` for negative and `1` for positive. This is good for us, as it makes classifying the tweets into a **Binary** classification problem, as opposed to a **Multi-class** one, considerably easier.\n",
    "\n",
    "##### Data Cleansing\n",
    "\n",
    "In order to perform sentiment analysis on the input data set, it needs to be simplified to remove a lot of the noise that exists in social media data and natural language in general.\n",
    "\n",
    "We need to create an input vector to the classifier that contains information about the words in the text, so the first step is to make all words lower-case, as this will reduce the dimensionality of the input vector. Then URLs are stripped from the text, as they are not useful to us. After this, punctuation and other useless characters are also removed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(target=0, text=u'is so sad for my apl friend')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_schema = StructType([\n",
    "    StructField(\"target\", IntegerType(), True),\n",
    "    StructField(\"text\", StringType(), True)\n",
    "])\n",
    "\n",
    "train_df = sess.read.csv(\"/cs/unique/ls99-kf39-cs5052/train/train.csv\", header=True, schema=sent_schema)\n",
    "\n",
    "train_clean = clean.clean_tweets(train_df, \"text\")\n",
    "train_clean.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in the training data, it is cleaned and split into a training and evaluation set. As there are 1.5 million tweets in total, we will only take 1% for eval, as this is still a large amount of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets in train: 1,434,200\n"
     ]
    }
   ],
   "source": [
    "train, evaluation = train_clean.randomSplit([0.99, 0.1], seed=42)\n",
    "print(\"Number of tweets in train: {:,}\".format(train.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "We have already trained a sentiment analysis pipeline and saved the model for reuse later, but should a user wish to train a new model on different data, it is a simple case of using the class we have defined called `SentimentAnalyser`.\n",
    "\n",
    "```python\n",
    "# Setup a new model pipeline\n",
    "model = SentimentAnalyser()\n",
    "\n",
    "# This will compute the vector representation of the tweets first, then train a Binary Classifier  \n",
    "model.train(train_data)  \n",
    "\n",
    "# Get the predictions\n",
    "predictions = model.predict(eval_data)  \n",
    "\n",
    "# Count the number of positive and negative tweets and return dataframes of positive + negative\n",
    "pos, neg = model.count_sentiments(predictions)  \n",
    "\n",
    "# Print the accuracy and RoC AUC \n",
    "model.classification_report(predictions)  \n",
    "\n",
    "# Save the model to disk for use later\n",
    "model.save(\"/path/to/save/to\")  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Loading Model\n",
    "\n",
    "The training and evaluation data was used to train a sentiment analysis pipeline, and the model weights were saved to disk, allowing the model to be re-used. Below, the next cell will load back in the model that we trained earlier and use it to compute sentiment scores for the cryptocurrency tweets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = \"/cs/unique/ls99-kf39-cs5052/models/\"\n",
    "\n",
    "sentiment_model = SentimentAnalyser()\n",
    "sentiment_model.load(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading KRAKEN_DASH_EUR.csv\n",
      "Loading KRAKEN_LTC_EUR.csv\n",
      "Loading KRAKEN_BTC_EUR.csv\n",
      "Loading KRAKEN_ETC_EUR.csv\n",
      "Loading KRAKEN_BCH_EUR.csv\n",
      "Loading KRAKEN_XMR_EUR.csv\n",
      "Loading KRAKEN_ETH_EUR.csv\n"
     ]
    }
   ],
   "source": [
    "alts = ['ETH']#['BTC', 'XMR', 'DASH', 'LTC', 'ETC', 'BCH']  # 'ETH'\n",
    "hashes = {\n",
    "        'ETH': ['%ethereum%', '%ether%', '%eth%'],\n",
    "        'BTC': ['%bitcoin%', '%btc%', '%bitcoin%'],\n",
    "        'XMR': [\"%monero%\", \"%xmr%\", \"%monero%\"], \n",
    "        'DASH': [\"%digital cash%\", \"%dash%\", \"%dash%\"], \n",
    "        'LTC': [\"%litecoin%\", \"%ltc%\", \"%litecoin%\"], \n",
    "        'ETC': [\"%ethereum classic%\", \"%etc%\", \"%eth classic%\"], \n",
    "        'BCH': [\"%bitcoincash%\", \"%bch%\", \"%bitcoin cash%\"]\n",
    "    }\n",
    "\n",
    "crypto_data = funcs.load_crypto()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at ETH\n",
      "rt @alttradex the alttradex ico starts tomorrow get your 20% bonus#alttradex #ico #bitcoin #ethereum… \n",
      "Tweets positive: 815,614, negative: 98,332\n",
      "Sentiment-Price correlation: -0.2772\n",
      "Sentiment-Return correlation: -0.0706\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for coin in alts:\n",
    "    hash = hashes[coin]\n",
    "    coin_df = df2.filter(fs.lower(df['text']).like(hash[0]) | fs.lower(df['text']).like(hash[1]) | fs.lower(df['text']).like(hash[2]))\n",
    "    coin_clean = clean.clean_tweets(coin_df, \"text\")\n",
    "    print(\"Looking at %s\" % coin)\n",
    "    print(coin_clean.first().text)\n",
    "    \n",
    "    coin_pred = sentiment_model.predict(coin_clean)\n",
    "    pos, neg = sentiment_model.count_sentiments(coin_pred)\n",
    "    \n",
    "    daily_pos = funcs.aggregate_by_day(pos)\n",
    "    daily_neg = funcs.aggregate_by_day(neg)\n",
    "    daily_pos.set_index(\"date\", inplace=True)\n",
    "    daily_neg.set_index(\"date\", inplace=True)\n",
    "    daily_pos.index = pd.to_datetime(daily_pos.index)\n",
    "    daily_neg.index = pd.to_datetime(daily_neg.index)\n",
    "    \n",
    "    daily_sent = pd.DataFrame(data={'pos':daily_pos['count'], 'neg':daily_neg['count']}, index=daily_pos.index)\n",
    "    daily_sent['pos'] = daily_sent['pos'].astype(float)\n",
    "    daily_sent['neg'] = daily_sent['neg'].astype(float)\n",
    "    daily_sent['sentiment'] = (daily_sent['pos'] - daily_sent['neg']) / (daily_sent['pos'] + daily_sent['neg'])\n",
    "    \n",
    "    # Fetch coin price data, combine with sentiment score and plot.\n",
    "    coin_df = crypto_data[coin]\n",
    "    sent_price = coin_df\n",
    "    sent_price['price'] = sent_price.weightedAverage\n",
    "    sent_price['return'] = sent_price.price.pct_change()\n",
    "    sent_price['sentiment'] = daily_sent['sentiment']\n",
    "    sent_price.dropna(inplace=True)\n",
    "    \n",
    "    double_plot([sent_price.price, sent_price.sentiment], \n",
    "                ['%s Price' % coin, 'Sentiment'], \n",
    "                ['Date', 'Price', 'Sentiment Score'], \n",
    "                \"%s Price vs Tweet Sentiment\" % coin, \n",
    "                sent_price.index.tolist())\n",
    "    double_plot([sent_price['return'], sent_price.sentiment], \n",
    "                ['%s Return' % coin, 'Sentiment'], \n",
    "                ['Date', 'Price', 'Sentiment Score'], \n",
    "                \"%s Return vs Tweet Sentiment\" % coin, \n",
    "                sent_price.index.tolist())\n",
    "    print(\"Sentiment-Price correlation: %.4f\" % sent_price.corr().sentiment.price)\n",
    "    print(\"Sentiment-Return correlation: %.4f\" % sent_price.corr()['sentiment']['return'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Results\n",
    "\n",
    "The results of the correlation analysis for daily sentiment scores and cryptocurrency price are given below. First, the raw output is listed, which shows the first tweet in the dataset for each coin, and then the calculated correlation scores and the graphs of price and return vs sentiment score per day.\n",
    "\n",
    "```\n",
    "Looking at ETH\n",
    "rt @alttradex the alttradex ico starts tomorrow get your 20% bonus#alttradex #ico #bitcoin #ethereum…\n",
    "Tweets positive: 815,614, negative: 98,332\n",
    "Sentiment-Price correlation: -0.2772\n",
    "Sentiment-Return correlation: -0.0706\n",
    "```\n",
    "\n",
    "![Price vs Sentiment](../img/ETH_Price_vs_Tweet_Sentiment.png)\n",
    "![Return vs Sentiment](../img/ETH_Return_vs_Tweet_Sentiment.png)\n",
    "\n",
    "```\n",
    "Looking at BTC\n",
    "rt @vinnylingham2x #bitcoin needs less developers and more incumbents and intermediaries\n",
    "Tweets positive: 2,753,006, negative: 403,501\n",
    "Sentiment-Price correlation: -0.1724\n",
    "Sentiment-Return correlation: -0.5240\n",
    "```\n",
    "\n",
    "![Price vs Sentiment](../img/BTC_Price_vs_Tweet_Sentiment.png)\n",
    "![Return vs Sentiment](../img/BTC_Return_vs_Tweet_Sentiment.png)\n",
    "\n",
    "```\n",
    "Looking at XMR\n",
    "rt @andrew0hayes genesis mining discountnpj8st#btc #ltc #eth #xmr #dash #str #gnt #dgb #stratis #xlm #eos #iota…\n",
    "Tweets positive: 34,201, negative: 8,696\n",
    "Sentiment-Price correlation: 0.8958\n",
    "Sentiment-Return correlation: 0.2364\n",
    "```\n",
    "\n",
    "![Price vs Sentiment](../img/XMR_Price_vs_Tweet_Sentiment.png)\n",
    "![Return vs Sentiment](../img/XMR_Return_vs_Tweet_Sentiment.png)\n",
    "\n",
    "```\n",
    "Looking at DASH\n",
    "rt @ken2020n 1027 あさイチ二宮和也1027 ロンドンハーツ2時間sp二宮和也1028 ラストレシピ公開直前！絶品グルメ打ち上げツアー二宮和也1029 鉄腕dash二宮和也112 アメトーーク二宮和也1112 相葉マナ…\n",
    "Tweets positive: 451,318, negative: 116,419\n",
    "Sentiment-Price correlation: -0.3727\n",
    "Sentiment-Return correlation: -0.6164\n",
    "```\n",
    "\n",
    "![Price vs Sentiment](../img/DASH_Price_vs_Tweet_Sentiment.png)\n",
    "![Return vs Sentiment](../img/DASH_Return_vs_Tweet_Sentiment.png)\n",
    "\n",
    "```\n",
    "Looking at LTC\n",
    "rt @andrew0hayes genesis mining discountnpj8st#btc #ltc #eth #xmr #dash #str #gnt #dgb #stratis #xlm #eos #iota…\n",
    "Tweets positive: 214,838, negative: 37,729\n",
    "Sentiment-Price correlation: 0.4713\n",
    "Sentiment-Return correlation: -0.0315\n",
    "```\n",
    "\n",
    "![Price vs Sentiment](../img/LTC_Price_vs_Tweet_Sentiment.png)\n",
    "![Return vs Sentiment](../img/LTC_Return_vs_Tweet_Sentiment.png)\n",
    "\n",
    "```\n",
    "Looking at ETC\n",
    "rt @andrew0hayes #genesismining code npj8st $etc $xmr #litecoin $ltc $steem $zec $dash $btc $eth $rep #eth…\n",
    "Tweets positive: 46,498, negative: 3,611\n",
    "Sentiment-Price correlation: -0.2842\n",
    "Sentiment-Return correlation: -0.5320\n",
    "```\n",
    "\n",
    "![Price vs Sentiment](../img/ETC_Price_vs_Tweet_Sentiment.png)\n",
    "![Return vs Sentiment](../img/ETC_Return_vs_Tweet_Sentiment.png)\n",
    "\n",
    "```\n",
    "Looking at BCH\n",
    "rt @lisaciarlone what the fork bitcoin cash community preps hard fork slated for november 13\n",
    "Tweets positive: 196,321, negative: 61,832\n",
    "Sentiment-Price correlation: 0.5710\n",
    "Sentiment-Return correlation: -0.1822\n",
    "```\n",
    "\n",
    "![Price vs Sentiment](../img/BCH_Price_vs_Tweet_Sentiment.png)\n",
    "![Return vs Sentiment](../img/BCH_Return_vs_Tweet_Sentiment.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Conclusion\n",
    "\n",
    "The results were somewhat mixed for the correlation analysis with sentiment. It looks like there is some strong correlation for a few currencies. However to fully explore the power of tweets for predicting cryptocurrency prices, more data is need. We only have 1 month of tweets and prices, which is not enough to build trading strategies from.\n",
    "\n",
    "Also, the tweets were only analysed for positive and negative sentiment. It may be better in future to use 3 classes for positive, neutral and negative. This \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
